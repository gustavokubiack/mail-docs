{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introdu\u00e7\u00e3o","text":""},{"location":"#objetivo-do-projeto","title":"Objetivo do Projeto","text":"<p>O projeto Mail tem como objetivo principal simular o processo de cadastro de um usu\u00e1rio em uma base de dados, seguido do envio de uma confirma\u00e7\u00e3o de que o cadastro foi realizado com sucesso. Esse fluxo visa representar um cen\u00e1rio comum de aplica\u00e7\u00f5es web modernas, envolvendo backend, frontend e uma infraestrutura escal\u00e1vel.</p>"},{"location":"#tecnologias-utilizadas","title":"Tecnologias Utilizadas","text":"<p>O projeto foi desenvolvido utilizando um conjunto de tecnologias modernas e bem estabelecidas no mercado:</p> <ul> <li>Backend</li> <li>Django: framework web robusto e escal\u00e1vel para Python.</li> <li> <p>Django REST Framework (DRF): biblioteca poderosa para a cria\u00e7\u00e3o de APIs RESTful com Django.</p> </li> <li> <p>Frontend</p> </li> <li>Vue.js: framework progressivo para constru\u00e7\u00e3o de interfaces web reativas.</li> <li> <p>Vite: ferramenta moderna de build extremamente r\u00e1pida, utilizada no projeto com Vue.js.</p> </li> <li> <p>Controle de Vers\u00e3o e Reposit\u00f3rio</p> </li> <li>Git: sistema de controle de vers\u00e3o distribu\u00eddo.</li> <li> <p>GitHub: plataforma de hospedagem de c\u00f3digo-fonte e colabora\u00e7\u00e3o.</p> </li> <li> <p>Infraestrutura</p> </li> <li>AWS (Amazon Web Services): provedora de nuvem utilizada para hospedar toda a infraestrutura do projeto.</li> <li>Amazon EKS (Elastic Kubernetes Service): servi\u00e7o gerenciado de Kubernetes utilizado para orquestrar os cont\u00eaineres do sistema de forma escal\u00e1vel e resiliente.</li> </ul> <p>Este conjunto de tecnologias foi escolhido visando garantir escalabilidade, manutenibilidade e ader\u00eancia \u00e0s boas pr\u00e1ticas de desenvolvimento e opera\u00e7\u00f5es modernas (DevOps e GitOps).</p>"},{"location":"aplicacao/","title":"Aplica\u00e7\u00e3o","text":""},{"location":"aplicacao/#descricao-da-aplicacao","title":"Descri\u00e7\u00e3o da Aplica\u00e7\u00e3o","text":"<p>A aplica\u00e7\u00e3o desenvolvida tem como objetivo simular o cadastro de um usu\u00e1rio interessado em um servi\u00e7o de e-mail. Ao realizar o cadastro, o sistema armazena os dados do usu\u00e1rio em um banco de dados e envia uma confirma\u00e7\u00e3o de inscri\u00e7\u00e3o por e-mail.</p> <p>Este fluxo representa uma funcionalidade comum em sistemas de marketing, newsletters ou plataformas SaaS que exigem confirma\u00e7\u00e3o de cadastro.</p>"},{"location":"aplicacao/#tecnologias-utilizadas","title":"Tecnologias Utilizadas","text":"<p>A stack da aplica\u00e7\u00e3o foi composta por tecnologias modernas, divididas entre backend, frontend e banco de dados:</p>"},{"location":"aplicacao/#backend","title":"\ud83d\udd39 Backend","text":"<ul> <li>Django: Framework web em Python, respons\u00e1vel pela l\u00f3gica de neg\u00f3cios e administra\u00e7\u00e3o.</li> <li>Django REST Framework (DRF): Utilizado para criar uma API RESTful, permitindo a comunica\u00e7\u00e3o entre frontend e backend.</li> <li>PostgreSQL: Banco de dados relacional utilizado para persist\u00eancia dos dados de cadastro.</li> </ul>"},{"location":"aplicacao/#frontend","title":"\ud83d\udd39 Frontend","text":"<ul> <li>Vue.js: Framework progressivo JavaScript para constru\u00e7\u00e3o de interfaces reativas.</li> <li>Vite: Ferramenta de build moderna, que oferece carregamento extremamente r\u00e1pido e suporte ao ecossistema Vue 3.</li> </ul>"},{"location":"aplicacao/#estrutura-de-deploy","title":"Estrutura de Deploy","text":"<p>O deploy da aplica\u00e7\u00e3o foi definido de forma declarativa com manifests Kubernetes organizados via Kustomize. Os arquivos YAML foram separados por servi\u00e7os:</p> <pre><code>\u2514\u2500\u2500 k8s/\n    \u251c\u2500\u2500 backend/\n    \u2502   \u251c\u2500\u2500 deployment.yaml\n    \u2502   \u251c\u2500\u2500 service.yaml\n    \u2502   \u2514\u2500\u2500 kustomization.yaml\n    \u251c\u2500\u2500 frontend/\n    \u2502   \u251c\u2500\u2500 deployment.yaml\n    \u2502   \u251c\u2500\u2500 service.yaml\n    \u2502   \u2514\u2500\u2500 kustomization.yaml\n    \u2514\u2500\u2500 kustomization.yaml\n</code></pre> <ul> <li>Kustomization raiz (<code>k8s/kustomization.yaml</code>) unifica ambos os ambientes, permitindo aplica\u00e7\u00e3o conjunta via ArgoCD.</li> </ul>"},{"location":"aplicacao/#acesso-a-aplicacao-no-cluster","title":"Acesso \u00e0 Aplica\u00e7\u00e3o no Cluster","text":"<p>A aplica\u00e7\u00e3o est\u00e1 exposta ao p\u00fablico utilizando um servi\u00e7o do tipo LoadBalancer, o que permite o acesso externo \u00e0 aplica\u00e7\u00e3o.</p>"},{"location":"cluster-kubernetes/","title":"Cluster Kubernetes","text":""},{"location":"cluster-kubernetes/#ferramenta-utilizada-para-instalacao","title":"Ferramenta Utilizada para Instala\u00e7\u00e3o","text":"<p>A instala\u00e7\u00e3o e gerenciamento do cluster Kubernetes foram realizados por meio do servi\u00e7o gerenciado Amazon Elastic Kubernetes Service (EKS), que simplifica o processo de cria\u00e7\u00e3o, atualiza\u00e7\u00e3o e escalabilidade de clusters Kubernetes na nuvem AWS.</p> <p>O EKS elimina a necessidade de instala\u00e7\u00e3o manual do plano de controle (control plane), oferecendo alta disponibilidade e seguran\u00e7a nativa, com integra\u00e7\u00e3o com diversos servi\u00e7os da AWS (IAM, VPC, CloudWatch, ELB, etc.).</p>"},{"location":"cluster-kubernetes/#configuracao-dos-nos","title":"Configura\u00e7\u00e3o dos N\u00f3s","text":""},{"location":"cluster-kubernetes/#estrutura","title":"Estrutura","text":"<p>O cluster foi configurado com:</p> <ul> <li>5 n\u00f3s de trabalho (worker nodes) </li> <li>0 n\u00f3s de controle (control plane gerenciado pelo EKS)</li> </ul> <p>Todos os n\u00f3s foram instanciados como EC2 do tipo <code>t3.micro</code>, compat\u00edveis com o Free Tier da AWS.</p>"},{"location":"cluster-kubernetes/#configuracoes-relevantes","title":"Configura\u00e7\u00f5es Relevantes","text":"<ul> <li> <p>Auto Scaling Manual:   O grupo de n\u00f3s foi configurado com um tamanho fixo de 5 inst\u00e2ncias (min, max e desired iguais a 5), para evitar flutua\u00e7\u00f5es no ambiente de simula\u00e7\u00e3o.</p> </li> <li> <p>Subnets P\u00fablicas:   Os n\u00f3s foram alocados em duas zonas de disponibilidade (<code>us-east-1a</code> e <code>us-east-1b</code>) em subnets p\u00fablicas, facilitando o acesso a servi\u00e7os e ferramentas como ArgoCD.</p> </li> <li> <p>IAM Role com Policies Necess\u00e1rias:   Cada n\u00f3 recebeu permiss\u00f5es espec\u00edficas via IAM Role para:</p> </li> <li>Comunica\u00e7\u00e3o com o EKS (<code>AmazonEKSWorkerNodePolicy</code>)</li> <li>Gerenciamento de rede (<code>AmazonEKS_CNI_Policy</code>)</li> <li> <p>Acesso ao ECR (<code>AmazonEC2ContainerRegistryReadOnly</code>)</p> </li> <li> <p>Cluster Security:   A comunica\u00e7\u00e3o entre os n\u00f3s e o plano de controle foi protegida por autentica\u00e7\u00e3o baseada em IAM. Al\u00e9m disso, um Security Group limitado foi utilizado para o banco de dados.</p> </li> </ul>"},{"location":"cluster-kubernetes/#validacao-do-funcionamento-do-cluster","title":"Valida\u00e7\u00e3o do Funcionamento do Cluster","text":"<p>Ap\u00f3s a cria\u00e7\u00e3o do cluster, foram realizados diversos testes para garantir que o ambiente estava funcional:</p>"},{"location":"cluster-kubernetes/#verificacao-de-infraestrutura","title":"\ud83d\udd0d Verifica\u00e7\u00e3o de Infraestrutura","text":"<ul> <li> <p>EC2 Dashboard (AWS Console):   Verifica\u00e7\u00e3o da cria\u00e7\u00e3o correta das 5 inst\u00e2ncias <code>t3.micro</code>, distribu\u00eddas entre duas zonas de disponibilidade.</p> </li> <li> <p>Subnets e Internet Gateway:   Checagem das subnets p\u00fablicas atribu\u00eddas aos n\u00f3s, e do roteamento correto via Internet Gateway.</p> </li> <li> <p>Verifica\u00e7\u00e3o do Cluster via CLI:</p> </li> </ul> <pre><code># Verificar contexto atual\nkubectl config get-contexts\n\n# Verificar status dos n\u00f3s\nkubectl get nodes\n\n# Verificar status dos pods do sistema\nkubectl get pods -n kube-system\n\n# Verificar status dos pods do ArgoCD\nkubectl get pods -n argocd\n\n# Verificar status dos pods da aplica\u00e7\u00e3o\nkubectl get pods -n default\n</code></pre>"},{"location":"conclusao/","title":"Conclus\u00e3o","text":""},{"location":"conclusao/#licoes-aprendidas","title":"Li\u00e7\u00f5es Aprendidas","text":"<p>Este projeto foi essencial para consolidar conhecimentos pr\u00e1ticos em integra\u00e7\u00e3o cont\u00ednua, entrega cont\u00ednua (CI/CD) e GitOps, al\u00e9m de proporcionar uma compreens\u00e3o mais profunda da orquestra\u00e7\u00e3o de aplica\u00e7\u00f5es em ambientes Kubernetes gerenciados.</p> <p>Foi poss\u00edvel aplicar conceitos de Infrastructure as Code (IaC) com Terraform, provisionar clusters escal\u00e1veis na AWS via EKS, e integrar o controle declarativo de aplica\u00e7\u00f5es com ArgoCD. O ciclo completo \u2014 da infraestrutura ao deploy automatizado via Git \u2014 refletiu cen\u00e1rios reais de produ\u00e7\u00e3o, o que permitiu aplicar esse aprendizado no ambiente profissional de forma pr\u00e1tica e imediata.</p>"},{"location":"conclusao/#dificuldades-encontradas","title":"Dificuldades Encontradas","text":"<p>A principal dificuldade t\u00e9cnica enfrentada esteve relacionada \u00e0 capacidade insuficiente dos n\u00f3s do cluster Kubernetes. Inicialmente, apenas uma inst\u00e2ncia EC2 do tipo <code>t3.micro</code> foi configurada, o que resultou em problemas de agendamento de pods.</p> <p>A limita\u00e7\u00e3o surgiu devido \u00e0 quantidade de pods padr\u00e3o consumidos por servi\u00e7os internos do EKS, como:</p> <ul> <li><code>aws-node</code></li> <li><code>kube-proxy</code></li> <li><code>coredns</code></li> <li>Componentes do ArgoCD</li> </ul> <p>Esses pods consomem slots que, em inst\u00e2ncias pequenas, comprometem o espa\u00e7o para os containers da aplica\u00e7\u00e3o. Foi necess\u00e1rio escalar manualmente o n\u00famero de n\u00f3s para 5 para garantir a estabilidade do cluster. A identifica\u00e7\u00e3o dessa causa e o ajuste da infraestrutura consumiram tempo significativo durante o desenvolvimento.</p>"},{"location":"conclusao/#o-que-faria-diferente","title":"O que Faria Diferente","text":"<p>Se fosse recome\u00e7ar o projeto, uma melhoria fundamental seria a configura\u00e7\u00e3o de um dom\u00edn`o personalizado. Durante o desenvolvimento, o acesso \u00e0 aplica\u00e7\u00e3o foi feito diretamente por meio da URL gerada pelo Elastic Load Balancer (ELB) da AWS, o que n\u00e3o \u00e9 ideal para ambientes de produ\u00e7\u00e3o.</p> <p>Essa melhoria aumentaria a ader\u00eancia do projeto a pr\u00e1ticas reais de deploy e opera\u00e7\u00e3o de sistemas em produ\u00e7\u00e3o.</p>"},{"location":"escolha-do-ambiente/","title":"Escolha do Ambiente","text":""},{"location":"escolha-do-ambiente/#tipo-de-ambiente-utilizado","title":"Tipo de Ambiente Utilizado","text":"<p>O ambiente escolhido para execu\u00e7\u00e3o do projeto foi nuvem p\u00fablica (Cloud), utilizando como provedor a Amazon Web Services (AWS). A aplica\u00e7\u00e3o foi implantada em um cluster Kubernetes gerenciado via Amazon EKS (Elastic Kubernetes Service).</p>"},{"location":"escolha-do-ambiente/#justificativa-da-escolha","title":"Justificativa da Escolha","text":"<p>A escolha da AWS como ambiente principal foi motivada pelo objetivo de simular um cen\u00e1rio real de produ\u00e7\u00e3o em empresas que utilizam computa\u00e7\u00e3o em nuvem para hospedar e escalar suas aplica\u00e7\u00f5es. A AWS oferece um conjunto robusto de servi\u00e7os gerenciados, integra\u00e7\u00e3o nativa com Kubernetes via EKS, al\u00e9m de uma camada gratuita (Free Tier) ideal para testes e simula\u00e7\u00f5es.</p> <p>Al\u00e9m disso, o uso de Kubernetes na nuvem facilita a orquestra\u00e7\u00e3o dos cont\u00eaineres da aplica\u00e7\u00e3o, oferecendo alta disponibilidade, balanceamento de carga, escalabilidade autom\u00e1tica e facilidade na integra\u00e7\u00e3o com pr\u00e1ticas de GitOps.</p>"},{"location":"escolha-do-ambiente/#descricao-das-instancias-criadas","title":"Descri\u00e7\u00e3o das Inst\u00e2ncias Criadas","text":"<p>Foram utilizadas 5 inst\u00e2ncias EC2 do tipo <code>t3.micro</code>, compat\u00edveis com o plano AWS Free Tier, para a composi\u00e7\u00e3o dos n\u00f3s do cluster Kubernetes.</p> Fun\u00e7\u00e3o Tipo de Inst\u00e2ncia vCPU Mem\u00f3ria Sistema Operacional N\u00f3 do cluster t3.micro 2 1 GB Amazon Linux 2 Total de n\u00f3s 5 inst\u00e2ncias \u2014 \u2014 \u2014 <p>Todas as inst\u00e2ncias foram provisionadas como n\u00f3s de trabalho (worker nodes) do cluster EKS. A gest\u00e3o do plano de controle (control plane) \u00e9 feita pela pr\u00f3pria AWS como parte do servi\u00e7o EKS, o que reduz a complexidade de configura\u00e7\u00e3o e manuten\u00e7\u00e3o.</p> <p>Esse setup se mostrou suficiente para o escopo do projeto e para demonstrar a viabilidade de uma aplica\u00e7\u00e3o em cont\u00eaineres rodando em um ambiente cloud-based real.</p>"},{"location":"gitops-argocd/","title":"GitOps com ArgoCD","text":""},{"location":"gitops-argocd/#instalacao-do-argocd","title":"Instala\u00e7\u00e3o do ArgoCD","text":"<p>O ArgoCD foi instalado automaticamente durante o provisionamento utilizando Helm integrado ao Terraform. Isso garante que a ferramenta de GitOps esteja dispon\u00edvel assim que o cluster for criado, mantendo o provisionamento 100% automatizado.</p> <p>A instala\u00e7\u00e3o utilizou:</p> <ul> <li>Helm Chart oficial do ArgoCD</li> <li>Reposit\u00f3rio Helm: <code>https://argoproj.github.io/argo-helm</code></li> <li>Vers\u00e3o: <code>5.46.7</code></li> <li>Namespace: <code>argocd</code> (criado automaticamente)</li> <li>Arquivo de valores personalizado: <code>argocd-values.yaml</code></li> </ul> <p>Perfeito! Aqui est\u00e1 a se\u00e7\u00e3o 5 \u2013 GitOps com ArgoCD refeita corretamente, com a marca\u00e7\u00e3o Markdown organizada, leg\u00edvel e t\u00e9cnica \u2014 pronta para ser salva como <code>5-gitops-com-argocd.md</code>.</p>"},{"location":"gitops-argocd/#repositorio-git-utilizado","title":"Reposit\u00f3rio Git Utilizado","text":"<p>O reposit\u00f3rio Git utilizado para o fluxo GitOps foi o GitHub, centralizando toda a l\u00f3gica de infraestrutura e de aplica\u00e7\u00f5es em uma \u00fanica fonte de verdade.</p>"},{"location":"gitops-argocd/#estrutura-do-repositorio-gitops","title":"Estrutura do Reposit\u00f3rio GitOps","text":"<p>A estrutura do reposit\u00f3rio segue o padr\u00e3o declarativo e modular, separando recursos de infraestrutura (Terraform) dos recursos de aplica\u00e7\u00e3o (Kubernetes).</p> <pre><code>\ud83d\udce6 reposit\u00f3rio/\n\u251c\u2500\u2500 terraform/         # Infraestrutura (EKS, RDS, VPC, IAM, etc.)\n\u2514\u2500\u2500 k8s/               # Manifests Kubernetes para deploy\n    \u251c\u2500\u2500 backend/\n    \u2502   \u251c\u2500\u2500 deployment.yaml\n    \u2502   \u251c\u2500\u2500 service.yaml\n    \u2502   \u2514\u2500\u2500 kustomization.yaml\n    \u251c\u2500\u2500 frontend/\n    \u2502   \u251c\u2500\u2500 deployment.yaml\n    \u2502   \u251c\u2500\u2500 service.yaml\n    \u2502   \u2514\u2500\u2500 kustomization.yaml\n    \u2514\u2500\u2500 kustomization.yaml   # Aponta para backend/ e frontend/\n</code></pre> <p>Essa estrutura permite que o ArgoCD acompanhe o diret\u00f3rio <code>k8s/</code> via Kustomize, simplificando o deploy e a manuten\u00e7\u00e3o das aplica\u00e7\u00f5es.</p>"},{"location":"gitops-argocd/#deploy-da-aplicacao-via-argocd","title":"Deploy da Aplica\u00e7\u00e3o via ArgoCD","text":""},{"location":"gitops-argocd/#o-deploy-da-aplicacao-foi-feito-manualmente-via-argocd-utilizando-a-interface-grafica-da-ferramenta-o-argocd-foi-configurado-para-apontar-para-o-diretorio-k8s-do-repositorio-git-e-sincroniza-os-recursos-de-acordo-com-os-manifests-definidos-no-repositorio","title":"O deploy da aplica\u00e7\u00e3o foi feito manualmente via ArgoCD, utilizando a interface gr\u00e1fica da ferramenta. O ArgoCD foi configurado para apontar para o diret\u00f3rio k8s/ do reposit\u00f3rio Git, e sincroniza os recursos de acordo com os manifests definidos no reposit\u00f3rio.","text":""},{"location":"gitops-argocd/#screenshots-do-argocd-funcionando","title":"Screenshots do ArgoCD Funcionando","text":"<p>Abaixo, uma imagem do ArgoCD mostrando o status dos deployments e servi\u00e7os da aplica\u00e7\u00e3o:</p>"},{"location":"gitops-argocd/#_1","title":"GitOps com ArgoCD","text":"<p>Com esse fluxo, qualquer altera\u00e7\u00e3o no reposit\u00f3rio Git dispara a atualiza\u00e7\u00e3o autom\u00e1tica no cluster Kubernetes, mantendo os ambientes sempre alinhados com o c\u00f3digo-fonte \u2014 princ\u00edpio central do GitOps.</p>"},{"location":"provisionamento/","title":"Provisionamento","text":""},{"location":"provisionamento/#ferramenta-utilizada","title":"Ferramenta Utilizada","text":"<p>Para o provisionamento da infraestrutura, foi utilizada a ferramenta Terraform, uma das mais robustas e populares solu\u00e7\u00f5es de Infrastructure as Code (IaC). O Terraform permite definir, versionar e aplicar configura\u00e7\u00f5es de infraestrutura de forma declarativa, com total controle e auditabilidade.</p>"},{"location":"provisionamento/#estrutura-de-provisionamento","title":"Estrutura de Provisionamento","text":"<p>A seguir, uma descri\u00e7\u00e3o das principais partes do c\u00f3digo Terraform utilizado:</p>"},{"location":"provisionamento/#vpc-e-subnets","title":"\ud83d\udd38 VPC e Subnets","text":"<p>Foi criada uma VPC personalizada com suporte a DNS e hostname, subdividida em:</p> <ul> <li>Subnets p\u00fablicas: destinadas ao cluster EKS.</li> <li>Subnets privadas: reservadas para o banco de dados PostgreSQL no RDS.</li> </ul> <p>Tamb\u00e9m foi configurado um Internet Gateway e uma Route Table para roteamento externo das subnets p\u00fablicas.</p>"},{"location":"provisionamento/#iam-roles-e-policies","title":"\ud83d\udd38 IAM Roles e Policies","text":"<p>Duas roles principais foram configuradas:</p> <ul> <li>eks_cluster_role: utilizada pelo plano de controle do EKS com a policy <code>AmazonEKSClusterPolicy</code>.</li> <li>eks_node_role: atribu\u00edda aos n\u00f3s do cluster com as seguintes policies:</li> <li><code>AmazonEKSWorkerNodePolicy</code></li> <li><code>AmazonEKS_CNI_Policy</code></li> <li><code>AmazonEC2ContainerRegistryReadOnly</code></li> </ul>"},{"location":"provisionamento/#cluster-eks","title":"\ud83d\udd38 Cluster EKS","text":"<p>O cluster Kubernetes foi criado com o nome <code>mail-cluster</code>, configurado para usar as subnets p\u00fablicas da VPC, com autentica\u00e7\u00e3o baseada em IAM Roles.</p>"},{"location":"provisionamento/#node-group","title":"\ud83d\udd38 Node Group","text":"<p>Foi criado um grupo de n\u00f3s com: - 5 inst\u00e2ncias EC2 <code>t3.micro</code> - Auto scaling fixo (min = 1, max = 5, desired = 5) - Tipo de inst\u00e2ncia compat\u00edvel com o Free Tier da AWS.</p> <p>Esses n\u00f3s foram associados \u00e0 role <code>eks_node_role</code> para comunica\u00e7\u00e3o adequada com o EKS e demais servi\u00e7os.</p>"},{"location":"provisionamento/#banco-de-dados-rds","title":"\ud83d\udd38 Banco de Dados (RDS)","text":"<p>Um banco de dados PostgreSQL foi provisionado usando <code>aws_db_instance</code> com: - 20 GB de armazenamento - Inst\u00e2ncia <code>db.t3.micro</code> - Subnets privadas e um Security Group configurado para permitir apenas acesso interno pela VPC (porta 5432).</p>"},{"location":"provisionamento/#helm-release-argocd","title":"\ud83d\udd38 Helm Release (ArgoCD)","text":"<p>O ArgoCD foi instalado via Helm no cluster EKS. A release foi definida como <code>argocd</code>, utilizando o reposit\u00f3rio oficial do projeto Argo Helm:</p> <ul> <li>Namespace: <code>argocd</code></li> <li>Chart: <code>argo-cd</code></li> <li>Vers\u00e3o: <code>5.46.7</code></li> <li>Arquivo customizado: <code>argocd-values.yaml</code></li> </ul>"},{"location":"provisionamento/#kubernetes-secrets","title":"\ud83d\udd38 Kubernetes Secrets","text":"<p>Foi criado um <code>Secret</code> Kubernetes com todas as vari\u00e1veis sens\u00edveis da aplica\u00e7\u00e3o, como:</p> <ul> <li>Dados do banco (host, user, senha)</li> <li>Configura\u00e7\u00f5es de e-mail</li> <li>Flags de debug</li> <li>Informa\u00e7\u00f5es de autentica\u00e7\u00e3o SMTP</li> </ul>"},{"location":"provisionamento/#desafios-e-solucoes","title":"Desafios e Solu\u00e7\u00f5es","text":""},{"location":"provisionamento/#capacidade-dos-nos-e-limite-de-pods","title":"\ud83d\udd38 Capacidade dos N\u00f3s e Limite de Pods","text":"<p>Inicialmente, o cluster foi configurado com apenas 1 n\u00f3 <code>t3.micro</code>, o que rapidamente gerou problemas de capacidade. Isso se deve ao fato de que:</p> <ul> <li>A AWS executa pods internos no cluster, como o <code>CoreDNS</code>, <code>kube-proxy</code>, <code>aws-node</code>, entre outros.</li> <li>A inst\u00e2ncia <code>t3.micro</code> tem um limite baixo de pods por n\u00f3 (aproximadamente 11 a 17, dependendo da configura\u00e7\u00e3o da ENI).</li> <li>A aplica\u00e7\u00e3o, ArgoCD e servi\u00e7os auxiliares tamb\u00e9m consomem pods.</li> </ul>"},{"location":"provisionamento/#solucao","title":"\ud83d\udd27 Solu\u00e7\u00e3o","text":"<p>Para resolver, foi realizado o aumento do n\u00famero de n\u00f3s de 1 para 5, garantindo maior disponibilidade de recursos para os pods do sistema e da aplica\u00e7\u00e3o, al\u00e9m de permitir uma opera\u00e7\u00e3o mais pr\u00f3xima da realidade de produ\u00e7\u00e3o.</p> <p>Esse ajuste resolveu os problemas de scheduling e permitiu a instala\u00e7\u00e3o e opera\u00e7\u00e3o est\u00e1vel do ArgoCD e da aplica\u00e7\u00e3o.</p>"},{"location":"provisionamento/#video-de-demonstracao","title":"V\u00eddeo de Demonstra\u00e7\u00e3o","text":""},{"location":"repositorio/","title":"Link para Reposit\u00f3rios","text":"<ul> <li>Backend: mail-api</li> <li>Frontend: mail-front</li> <li>Infraestrutura/GitOps: mail-ops</li> <li>Documenta\u00e7\u00e3o: mail-docs</li> </ul>"}]}